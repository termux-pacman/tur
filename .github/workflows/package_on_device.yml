# Based on https://github.com/termux/termux-packages/blob/595969f581655e8cbf65182cf84bd5ffb2cf7b89/.github/workflows/packages.yml
##
##  Copyright 2020 Termux
##
##  Licensed under the Apache License, Version 2.0 (the "License");
##  you may not use this file except in compliance with the License.
##  You may obtain a copy of the License at
##
##    http://www.apache.org/licenses/LICENSE-2.0
##
##  Unless required by applicable law or agreed to in writing, software
##  distributed under the License is distributed on an "AS IS" BASIS,
##  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##  See the License for the specific language governing permissions and
##  limitations under the License.
##

name: Packages-TUR-on-Device

on:
  push:
    branches:
    - master
    paths:
    - 'tur-on-device/**'
  pull_request:
    paths:
    - 'tur-on-device/**'
  workflow_dispatch:
    inputs:
      packages:
        description: "A space-separated names of packages selected for rebuilding"
        required: true

jobs:
  build-x86:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        target_arch: [i686, x86_64]
      fail-fast: false
    steps:
    - name: Clone repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1000
        path: ${{ github.workspace }}
    - name: Merge repos
      run: ./setup-environment.sh
    - name: Gather build summary
      run: |
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          BASE_COMMIT=$(jq --raw-output .pull_request.base.sha "$GITHUB_EVENT_PATH")
          OLD_COMMIT=$(jq --raw-output .commits[0].id "$GITHUB_EVENT_PATH")
          HEAD_COMMIT=$(jq --raw-output .commits[-1].id "$GITHUB_EVENT_PATH")
          if [ "$BASE_COMMIT" = "null" ]; then
            if [ "$OLD_COMMIT" = "$HEAD_COMMIT" ]; then
              # Single-commit push.
              echo "Processing commit: ${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${HEAD_COMMIT}")
            else
              # Multi-commit push.
              OLD_COMMIT="${OLD_COMMIT}~1"
              echo "Processing commit range: ${OLD_COMMIT}..${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${OLD_COMMIT}" "${HEAD_COMMIT}")
            fi
          else
            # Pull requests.
            echo "Processing pull request #$(jq --raw-output .pull_request.number "$GITHUB_EVENT_PATH"): ${BASE_COMMIT}..HEAD"
            CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${BASE_COMMIT}" "HEAD")
          fi
        fi
        mkdir -p ./artifacts ./pkgs
        touch ./pkgs/.placeholder
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          # Process tag '%ci:no-build' that may be added as line to commit message.
          # Forces CI to cancel current build with status 'passed'
          if grep -qiP '^\s*%ci:no-build\s*$' <(git log --format="%B" -n 1 "HEAD"); then
            tar cf artifacts/pkgs-${{ matrix.target_arch }}.tar pkgs
            echo "[!] Force exiting as tag '%ci:no-build' was applied to HEAD commit message."
            exit 0
          fi
          for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
            repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
            # Parse changed files and identify new packages and deleted packages.
            # Create lists of those packages that will be passed to upload job for
            # further processing.
            while read -r file; do
              if ! [[ $file == ${repo_path}/* ]]; then
                # This file does not belong to a package, so ignore it
                continue
              fi
              if [[ $file =~ ^${repo_path}/([.a-z0-9+-]*)/([.a-z0-9+-]*).subpackage.sh$ ]]; then
                # A subpackage was modified, check if it was deleted or just updated
                pkg=${BASH_REMATCH[1]}
                subpkg=${BASH_REMATCH[2]}
                if [ ! -f "${repo_path}/${pkg}/${subpkg}.subpackage.sh" ]; then
                  echo "$subpkg" >> ./deleted_${repo}_packages.txt
                fi
              elif [[ $file =~ ^${repo_path}/([.a-z0-9+-]*)/.*$ ]]; then
                # package, check if it was deleted or updated
                pkg=${BASH_REMATCH[1]}
                if [ -d "${repo_path}/${pkg}" ]; then
                  echo "$pkg" >> ./built_${repo}_packages.txt
                  # If there are subpackages we want to create a list of those
                  # as well
                  for file in $(find "${repo_path}/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
                    echo "$(basename "${file%%.subpackage.sh}")" >> ./built_${repo}_subpackages.txt
                  done
                else
                  echo "$pkg" >> ./deleted_${repo}_packages.txt
                fi
              fi
            done<<<${CHANGED_FILES}
          done
        else
          for pkg in ${{ github.event.inputs.packages }}; do
            repo_paths=$(jq --raw-output 'keys | .[]' repo.json)
            found=false
            for repo_path in $repo_paths; do
              repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
              if [ -d "${repo_path}/${pkg}" ]; then
                found=true
                echo "$pkg" >> ./built_${repo}_packages.txt
                for subpkg in $(find "${repo_path}/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
                  echo "$(basename "${subpkg%%.subpackage.sh}")" >> ./built_${repo}_subpackages.txt
                done
              fi
            done
            if [ "$found" != true ]; then
              echo "Package '${pkg}' not found in any of the repo"
              exit 1
            fi
          done
        fi
        for repo in $(jq --raw-output '.[].name' repo.json); do
          # Fix so that lists do not contain duplicates
          if [ -f ./built_${repo}_packages.txt ]; then
            uniq ./built_${repo}_packages.txt > ./built_${repo}_packages.txt.tmp
            mv ./built_${repo}_packages.txt.tmp ./built_${repo}_packages.txt
          fi
          if [ -f ./built_${repo}_subpackages.txt ]; then
            uniq ./built_${repo}_subpackages.txt > ./built_${repo}_subpackages.txt.tmp
            mv ./built_${repo}_subpackages.txt.tmp ./built_${repo}_subpackages.txt
          fi
          if [ -f ./deleted_${repo}_packages.txt ]; then
            uniq ./deleted_${repo}_packages.txt > ./deleted_${repo}_packages.txt.tmp
            mv ./deleted_${repo}_packages.txt.tmp ./deleted_${repo}_packages.txt
          fi
        done
    - name: Free additional disk space (if necessary)
      run: |
        if grep -q '^demo1$\|^demo2$' ./built_tur_packages.txt; then
          echo "Free additional disk space on host"
          sudo apt purge -yq $(dpkg -l | grep '^ii' | awk '{ print $2 }' | grep -P '(cabal-|dotnet-|ghc-|libmono|php)') \
            liblldb-6.0 libllvm6.0:amd64 mono-runtime-common monodoc-manual powershell ruby
          sudo apt autoremove -yq
          sudo rm -rf /opt/hostedtoolcache /usr/local /usr/share/dotnet /usr/share/swift
        fi
    - name: Lint packages
      run: |
        declare -a package_recipes
        for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
          repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
          if [ -f ./built_${repo}_packages.txt ]; then
            package_recipes="$package_recipes $(cat ./built_${repo}_packages.txt | repo_path=${repo_path} awk '{print ENVIRON["repo_path"]"/"$1"/build.sh"}')"
          fi
        done
        if [ ! -z "$package_recipes" ]; then
          ./scripts/lint-packages.sh $package_recipes
        fi
    - name: Build packages
      env:
        ARCH: ${{ matrix.target_arch }}
      run: |
        ./common-files/build-termux-docker.sh login ./scripts/setup-termux.sh
        docker system prune -a -f
        declare -a packages
        for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
          repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
          if [ -f ./built_${repo}_packages.txt ]; then
            packages="$packages $(cat ./built_${repo}_packages.txt)"
          fi
        done
        sudo chown -R 1000:1000 $(pwd)
        if [ ! -z "$packages" ]; then
          ./common-files/build-termux-docker.sh login ./build-package.sh --format pacman -I $packages
        fi
    - name: Generate build artifacts
      if: always()
      run: |
        sudo chown -R $(id -u):$(id -u) $(pwd)
        for repo in $(jq --raw-output '.[].name' repo.json); do
          # Put package lists into directory with *.pkg.* files so they will be transferred to
          # upload job.
          test -f ./built_${repo}_packages.txt && mv ./built_${repo}_packages.txt ./pkgs/
          test -f ./built_${repo}_subpackages.txt && cat ./built_${repo}_subpackages.txt >> ./pkgs/built_${repo}_packages.txt \
            && rm ./built_${repo}_subpackages.txt
          test -f ./deleted_${repo}_packages.txt && mv ./deleted_${repo}_packages.txt ./pkgs/
          # Move only pkgs from built_packages into pkgs/ folder before
          # creating an archive.
          while read -r pkg; do
            # Match both $pkg.pkg.* and $pkg-static.pkg.*.
            find output \( -name "$pkg_*.pkg.*" -o -name "$pkg-static_*.pkg.*" \) -type f -print0 | xargs -0r mv -t pkgs/
          done < <(cat ./pkgs/built_${repo}_packages.txt)
        done
        # Files containing certain symbols (e.g. ":") will cause failure in actions/upload-artifact.
        # Archiving *.pkg.* files in a tarball to avoid issues with uploading.
        tar cf artifacts/pkgs-${{ matrix.target_arch }}-${{ github.sha }}.tar pkgs
        rm -rf output
    - name: Checksums for built *.pkg.* files
      if: always()
      run: |
        find pkgs -type f -name "*.pkg.*" -exec sha256sum "{}" \; | sort -k2
    - name: Store *.pkg.* files
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pkgs-${{ matrix.target_arch }}-${{ github.sha }}
        path: ./artifacts

  build-arm:
    runs-on: self-hosted
    strategy:
      matrix:
        target_arch: [arm, aarch64]
      fail-fast: false
    steps:
    - name: Clone repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1000
        path: ${{ github.workspace }}
    - name: Merge repos
      run: ./setup-environment.sh
    - name: Gather build summary
      run: |
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          BASE_COMMIT=$(jq --raw-output .pull_request.base.sha "$GITHUB_EVENT_PATH")
          OLD_COMMIT=$(jq --raw-output .commits[0].id "$GITHUB_EVENT_PATH")
          HEAD_COMMIT=$(jq --raw-output .commits[-1].id "$GITHUB_EVENT_PATH")
          if [ "$BASE_COMMIT" = "null" ]; then
            if [ "$OLD_COMMIT" = "$HEAD_COMMIT" ]; then
              # Single-commit push.
              echo "Processing commit: ${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${HEAD_COMMIT}")
            else
              # Multi-commit push.
              OLD_COMMIT="${OLD_COMMIT}~1"
              echo "Processing commit range: ${OLD_COMMIT}..${HEAD_COMMIT}"
              CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${OLD_COMMIT}" "${HEAD_COMMIT}")
            fi
          else
            # Pull requests.
            echo "Processing pull request #$(jq --raw-output .pull_request.number "$GITHUB_EVENT_PATH"): ${BASE_COMMIT}..HEAD"
            CHANGED_FILES=$(git diff-tree --no-commit-id --name-only -r "${BASE_COMMIT}" "HEAD")
          fi
        fi
        mkdir -p ./artifacts ./pkgs
        touch ./pkgs/.placeholder
        if [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
          # Process tag '%ci:no-build' that may be added as line to commit message.
          # Forces CI to cancel current build with status 'passed'
          if grep -qiP '^\s*%ci:no-build\s*$' <(git log --format="%B" -n 1 "HEAD"); then
            tar cf artifacts/pkgs-${{ matrix.target_arch }}.tar pkgs
            echo "[!] Force exiting as tag '%ci:no-build' was applied to HEAD commit message."
            exit 0
          fi
          for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
            repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
            # Parse changed files and identify new packages and deleted packages.
            # Create lists of those packages that will be passed to upload job for
            # further processing.
            while read -r file; do
              if ! [[ $file == ${repo_path}/* ]]; then
                # This file does not belong to a package, so ignore it
                continue
              fi
              if [[ $file =~ ^${repo_path}/([.a-z0-9+-]*)/([.a-z0-9+-]*).subpackage.sh$ ]]; then
                # A subpackage was modified, check if it was deleted or just updated
                pkg=${BASH_REMATCH[1]}
                subpkg=${BASH_REMATCH[2]}
                if [ ! -f "${repo_path}/${pkg}/${subpkg}.subpackage.sh" ]; then
                  echo "$subpkg" >> ./deleted_${repo}_packages.txt
                fi
              elif [[ $file =~ ^${repo_path}/([.a-z0-9+-]*)/.*$ ]]; then
                # package, check if it was deleted or updated
                pkg=${BASH_REMATCH[1]}
                if [ -d "${repo_path}/${pkg}" ]; then
                  echo "$pkg" >> ./built_${repo}_packages.txt
                  # If there are subpackages we want to create a list of those
                  # as well
                  for file in $(find "${repo_path}/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
                    echo "$(basename "${file%%.subpackage.sh}")" >> ./built_${repo}_subpackages.txt
                  done
                else
                  echo "$pkg" >> ./deleted_${repo}_packages.txt
                fi
              fi
            done<<<${CHANGED_FILES}
          done
        else
          for pkg in ${{ github.event.inputs.packages }}; do
            repo_paths=$(jq --raw-output 'keys | .[]' repo.json)
            found=false
            for repo_path in $repo_paths; do
              repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
              if [ -d "${repo_path}/${pkg}" ]; then
                found=true
                echo "$pkg" >> ./built_${repo}_packages.txt
                for subpkg in $(find "${repo_path}/${pkg}/" -maxdepth 1 -type f -name \*.subpackage.sh | sort); do
                  echo "$(basename "${subpkg%%.subpackage.sh}")" >> ./built_${repo}_subpackages.txt
                done
              fi
            done
            if [ "$found" != true ]; then
              echo "Package '${pkg}' not found in any of the repo"
              exit 1
            fi
          done
        fi
        for repo in $(jq --raw-output '.[].name' repo.json); do
          # Fix so that lists do not contain duplicates
          if [ -f ./built_${repo}_packages.txt ]; then
            uniq ./built_${repo}_packages.txt > ./built_${repo}_packages.txt.tmp
            mv ./built_${repo}_packages.txt.tmp ./built_${repo}_packages.txt
          fi
          if [ -f ./built_${repo}_subpackages.txt ]; then
            uniq ./built_${repo}_subpackages.txt > ./built_${repo}_subpackages.txt.tmp
            mv ./built_${repo}_subpackages.txt.tmp ./built_${repo}_subpackages.txt
          fi
          if [ -f ./deleted_${repo}_packages.txt ]; then
            uniq ./deleted_${repo}_packages.txt > ./deleted_${repo}_packages.txt.tmp
            mv ./deleted_${repo}_packages.txt.tmp ./deleted_${repo}_packages.txt
          fi
        done
    - name: Lint packages
      run: |
        declare -a package_recipes
        for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
          repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
          if [ -f ./built_${repo}_packages.txt ]; then
            package_recipes="$package_recipes $(cat ./built_${repo}_packages.txt | repo_path=${repo_path} awk '{print ENVIRON["repo_path"]"/"$1"/build.sh"}')"
          fi
        done
        if [ ! -z "$package_recipes" ]; then
          ./scripts/lint-packages.sh $package_recipes
        fi
    - name: Build packages
      env:
        ARCH: ${{ matrix.target_arch }}
      run: |
        ./common-files/build-termux-docker.sh login ./scripts/setup-termux.sh
        declare -a packages
        for repo_path in $(jq --raw-output 'keys | .[]' repo.json); do
          repo=$(jq --raw-output '.["'${repo_path}'"].name' repo.json)
          if [ -f ./built_${repo}_packages.txt ]; then
            packages="$packages $(cat ./built_${repo}_packages.txt)"
          fi
        done
        sudo chown -R 1000:1000 $(pwd)
        if [ ! -z "$packages" ]; then
          ./common-files/build-termux-docker.sh login ./build-package.sh --format pacman -I $packages
        fi
    - name: Clean up docker containers
      env:
        ARCH: ${{ matrix.target_arch }}
      if: always()
      run: ./common-files/clean-termux-docker.sh
    - name: Generate build artifacts
      if: always()
      run: |
        sudo chown -R $(id -u):$(id -u) $(pwd)
        for repo in $(jq --raw-output '.[].name' repo.json); do
          # Put package lists into directory with *.pkg.* files so they will be transferred to
          # upload job.
          test -f ./built_${repo}_packages.txt && mv ./built_${repo}_packages.txt ./pkgs/
          test -f ./built_${repo}_subpackages.txt && cat ./built_${repo}_subpackages.txt >> ./pkgs/built_${repo}_packages.txt \
            && rm ./built_${repo}_subpackages.txt
          test -f ./deleted_${repo}_packages.txt && mv ./deleted_${repo}_packages.txt ./pkgs/
          # Move only pkgs from built_packages into pkgs/ folder before
          # creating an archive.
          while read -r pkg; do
            # Match both $pkg.pkg.* and $pkg-static.pkg.*.
            find output \( -name "$pkg_*.pkg.*" -o -name "$pkg-static_*.pkg.*" \) -type f -print0 | xargs -0r mv -t pkgs/
          done < <(cat ./pkgs/built_${repo}_packages.txt)
        done
        # Files containing certain symbols (e.g. ":") will cause failure in actions/upload-artifact.
        # Archiving *.pkg.* files in a tarball to avoid issues with uploading.
        tar cf artifacts/pkgs-${{ matrix.target_arch }}-${{ github.sha }}.tar pkgs
        rm -rf output
    - name: Checksums for built *.pkg.* files
      if: always()
      run: |
        find pkgs -type f -name "*.pkg.*" -exec sha256sum "{}" \; | sort -k2
    - name: Store *.pkg.* files
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pkgs-${{ matrix.target_arch }}-${{ github.sha }}
        path: ./artifacts
    - name: Remove pkgs
      if: always()
      run: |
        rm -rf ./artifacts ./pkgs

  upload:
    permissions:
      contents: read
    if: github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        arch: [aarch64, arm, i686, x86_64]
      fail-fast: false
    steps:
    - name: Clone repository
      uses: actions/checkout@v4
    - name: Get *.pkg.* files
      uses: actions/download-artifact@v4.1.7
      with:
        path: ./
    - name: Install aws-cli
      run: |
        git clone https://github.com/termux-pacman/aws-cli-action.git
        ./aws-cli-action/setup.sh '${{ secrets.AWS_ACCESS_KEY_ID }}' '${{ secrets.AWS_ACCESS_KEY }}' '${{ secrets.AWS_REGION }}'
    - name: Import GPG key
      run: |
        echo '${{ secrets.SF_GPG_BOT }}' > key.gpg
        gpg --pinentry-mode=loopback --passphrase '${{ secrets.PW_GPG_BOT }}' --import key.gpg > /dev/null
        rm key.gpg
    - name: Uploading packages to aws
      run: |
        source ./aws-cli-action/func.sh
        sfuf() {
          gpg --batch --pinentry-mode=loopback --passphrase '${{ secrets.PW_GPG_BOT }}' --detach-sign --use-agent -u '${{ secrets.KEY_GPG_BOT }}' --no-armor "$1"
          for format_file in "" ".sig"; do
            aws s3 cp "${1}${format_file}" s3://'${{ secrets.SFPU }}'/${repo}/${{ matrix.arch }}/"${1##*/}${format_file}"
          done
          rm "$1.sig"
        }
        tar xf "pkgs-${{ matrix.arch }}-${{ github.sha }}/pkgs-${{ matrix.arch }}-${{ github.sha }}.tar"
        for repo in $(jq --raw-output '.[].name' repo.json); do
          dp_file="deleted_${repo}_packages.txt"
          if [[ -f pkgs/$dp_file ]]; then
            path_dp_file=pkgs/${{ github.sha }}_${dp_file}
            mv pkgs/${dp_file} ${path_dp_file}
            sfuf "${path_dp_file}"
          fi
          for name_pkg in $(cat ./pkgs/built_${repo}_packages.txt); do
            for list_pkg in pkgs/*.pkg.*; do
              dir_pkg_sp=(${list_pkg//// })
              for static in "" "-static"; do
                if [[ $(echo "${name_pkg}${static}" | sed 's/+/0/g') = $(get_name ${dir_pkg_sp[-1]}) ]]; then
                  sfuf "$list_pkg"
                fi
              done
            done
          done
        done
